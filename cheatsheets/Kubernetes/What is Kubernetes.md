# Что такое Kubernetes

---

## 1. Что такое Kubernetes по-простому

**Kubernetes (k8s)** — это система, которая:

- запускает приложения в контейнерах (обычно Docker),
- размазывает их по куче машин (кластер),
- следит, чтобы всё жило, перезапускается и масштабируется.

Если очень грубо:

> "Хочу 5 экземпляров вот этого сервиса", а Kubernetes сам решает:
> 
- на каких серверах их запустить,
- как их связать друг с другом,
- как дать к ним доступ извне,
- как их обновлять без простоя.

---

## 2. Зачем вообще нужен Kubernetes

До Kubernetes было так:

- Есть несколько серверов.
- Ты деплоишь на них руками / скриптами.
- Ломается что-то на одном — всё падает.
- Надо обновить версию — боль, даунтаймы, костыли.

### Kubernetes решает такие проблемы:

1. **Масштабирование**
    
    Надо больше мощи? Просто меняешь число реплик: `replicas: 10`. Он сам поднимет больше контейнеров.
    
2. **Отказоустойчивость**
    
    Упал один нод — Pod’ы переезжают на другие. Приложение продолжает работать.
    
3. **Авто-перезапуск**
    
    Контейнер умер → k8s его перезапустит. Завис → он его убьёт и поднимет новый (если правильно настроены probes).
    
4. **Обновления без даунтайма** (rolling updates)
    
    Новая версия выкатывается постепенно: часть старых Pod’ов меняется на новые → трафик перераспределяется.
    
5. **Одинаковая среда**
    
    Dev, stage, prod — всё на одном и том же механизме: манифесты, контейнеры.
    
6. **Управление конфигами и секретами**
    
    Secrets, ConfigMaps — удобно хранить пароли, доступы и конфиги.
    

---

## 3. Из чего состоит кластер Kubernetes

Кластер = **control plane** + **worker-ноды**

### 3.1. Control Plane (мозг)

Тут живёт управление:

- **kube-apiserver** — Входная точка для всего. Всё общение с кластером — через него (`kubectl` бьёт сюда).
- **etcd** — Хранилище состояния (ключ-значение). Всё, что «знает» кластер: какие Pod’ы, ноды, конфиги — лежит тут.
- **kube-scheduler** — Решает, на какой нод отправить новый Pod, глядя на:
    - ресурсы,
    - ограничения,
    - taints/tolerations,
    - affinity/anti-affinity.
- **kube-controller-manager** — Контроллеры, которые смотрят: «как *должно быть*» vs «как *есть*» и приводят к желаемому состоянию:
    - ReplicaSet controller,
    - Node controller,
    - Job controller и т.д.

Идея простая:

Ты описываешь **desired state** (манифесты), контроллеры приводят реальность к этому состоянию.

---

### 3.2. Worker-ноды (рабочие машины)

Это сервера, которые реально выполняют твой код.

На каждой ноде:

- **kubelet** — Агент, который:
    - получает от control plane: «запусти эти Pod’ы»,
    - следит за их состоянием,
    - отчитывается обратно.
- **kube-proxy** — Настраивает сетевые правила (iptables/ipvs), чтобы трафик ходил по Service’ам.
- **Container runtime** — Docker, containerd, CRI-O — то, что реально запускает контейнеры.

---

## 4. Основные объекты Kubernetes (то, чем ты будешь крутить кластер)

### 4.1. Pod

**Pod** — минимальная единица деплоя. Это **1 или несколько контейнеров**, которые:

- всегда на одном ноде,
- делят между собой:
    - сеть (один IP),
    - volume’ы (файлы).

Обычно — 1 контейнер в Pod’е. Множественные — только для «sidecar» (логирование, прокси и т.п.).

---

### 4.2. Deployment

**Deployment** — описывает:

- образ контейнера,
- сколько реплик,
- стратегию обновления.

Он создаёт **ReplicaSet**, который уже держит нужное количество Pod’ов.

Пример:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
        - name: my-app
          image: nginx:1.27
          ports:
            - containerPort: 80

```

---

### 4.3. Service

**Service** — это стабильная точка доступа к Pod’ам.

Проблема: Pod’ы:

- могут умирать/перезапускаться,
- менять IP.

Service:

- смотрит на **labels**,
- автоматически держит список живых Pod’ов,
- балансирует трафик между ними.

Типы Service:

- `ClusterIP` — доступно **только внутри кластера**.
- `NodePort` — открывает порт на ноде (порт примерно 30000–32767).
- `LoadBalancer` — интеграция с облаком, внешний IP от балансировщика.

---

### 4.4. Ingress

**Ingress** — это правило уровня L7 (HTTP/HTTPS), которое:

- решает, куда отправить запрос по пути / хосту,
- часто работает через Ingress Controller (Nginx, Traefik, etc).

Например:

- `api.example.com` → сервис `backend`
- `app.example.com` → сервис `frontend`

---

### 4.5. ConfigMap и Secret

- **ConfigMap** — обычные конфиги (например, `APP_MODE=prod`).
- **Secret** — «чувствительные» данные (пароли, токены, ключи).

Подключаются:

- как переменные окружения,
- как файлы в volume.

---

### 4.6. Volume и Storage

Kubernetes сам по себе диски не хранит, он умеет подключать:

- локальные,
- сетевые (NFS, Ceph, EBS, GCE PD, и т.д.).

Основные объекты:

- **PersistentVolume (PV)** — реальный кусок хранилища.
- **PersistentVolumeClaim (PVC)** — запрос от приложения: «мне нужен диск такой-то ёмкости и класса».

Приложение видит только PVC.

---

## 5. Как всё работает шаг за шагом

Представим, что деплоим веб-приложение:

1. Пишем манифесты:
    - Deployment (образ, переменные, порты),
    - Service (как до него достучаться),
    - Ingress (домен, пути),
    - PVC (если нужен диск).
2. Применяем: `kubectl apply -f .`
3. kube-apiserver записывает desired state в etcd.
4. Контроллеры видят:
    - нужен новый Deployment → создают ReplicaSet,
    - ReplicaSet создаёт нужное число Pod’ов.
5. Scheduler решает:
    - «этот Pod пойдёт на ноду N1, а этот — на N2».
6. Kubelet на ноде:
    - скачивает образ,
    - запускает контейнеры,
    - проверяет их живость (liveness/readiness probes).
7. Service:
    - обнаруживает новые Pod’ы по label’ам,
    - начинает прокидывать на них трафик.
8. Ingress:
    - получает внешний запрос,
    - по правилу отправляет его в нужный Service,
    - Service — на Pod’ы.